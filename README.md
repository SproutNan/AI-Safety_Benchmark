<div align="center">

# AI-Safety GuidedBench

<p>
    <a href="https://arxiv.org/abs/2502.16903" target="_blank">
        <img src="https://img.shields.io/badge/cs.CL-2502.16903-b31b1b?logo=arxiv&logoColor=red" alt="arXiv"/>
    </a>
    <a href="mailto:rhuangbi@connect.ust.hk" target="_blank">
        <img alt="email" src="https://img.shields.io/badge/ðŸ“® enquiry-blue">
    </a>
</p>

</div>

This is the code for our paper *<strong>GuidedBench: Equipping Jailbreak Evaluation with Guidelines</strong>*.

## News

- [2025-02-26] The demo code for evaluation is released.
- [2025-02-25] The paper is available on arXiv.

## Citation

If you find this work helpful, please consider citing our paper:

```bibtex
@article{huang2025guidedbench,
  title   = {GuidedBench: Equipping Jailbreak Evaluation with Guidelines},
  author  = {Ruixuan Huang and Xunguang Wang and Zongjie Li and Daoyuan Wu and Shuai Wang},
  year    = {2025},
  journal = {arXiv preprint arXiv: 2502.16903}
}
```
